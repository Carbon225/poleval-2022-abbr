method: bayes
metric:
  goal: maximize
  name: eval/aw
parameters:
  checkpoint:
    value: ./models/plt5-wiki

  per_device_train_batch_size:
    value: 64
  per_device_eval_batch_size:
    value: 64
  gradient_accumulation_steps:
    value: 4

  dataset:
    value: poleval+kw

  do_eval:
    value: true
  do_train:
    value: true

  seed:
    value: 0

  optim:
    values:
    - adamw_torch
    - adafactor

  learning_rate:
    distribution: log_uniform_values
    max: 0.1
    min: 1e-06

  num_train_epochs:
    distribution: q_uniform
    max: 50
    min: 5

  weight_decay:
    distribution: uniform
    max: 0.1
    min: 0
program: train.py
